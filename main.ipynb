{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from src.create_annotations import *\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import morphology\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.transform import rotate\n",
    "from skimage import exposure\n",
    "from skimage.filters import unsharp_mask\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "from skimage.transform import resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "image_list2 = []\n",
    "for filename in glob.glob('dataset/input_images/*.jpg'):  # Assuming images are in JPG format\n",
    "    im = Image.open(filename)\n",
    "    image_list.append(im)\n",
    "    image_list2.append(im.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skew Correction. ...\n",
    "Image Scaling. ...\n",
    "Noise Removal. ...\n",
    "Thinning and Skeletonization. ...\n",
    "Gray Scale image. ...\n",
    "Thresholding or Binarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deskew(image):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Otsu's thresholding\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the largest contour\n",
    "    contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Get the minimum bounding rectangle of the contour\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    angle = rect[2]\n",
    "\n",
    "    # Rotate the image to correct skew\n",
    "    if angle < -45:\n",
    "        angle += 90\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "    return rotated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_image(image, size=(200, 200)):\n",
    "    return cv2.resize(image, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(image):\n",
    "    return cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thin_skeletonize(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_image = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    skeletonized_image = morphology.skeletonize(binary_image / 255)\n",
    "    return cv2.cvtColor(skeletonized_image.astype(np.uint8) * 255, cv2.COLOR_GRAY2BGR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_image(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    threshold_value = threshold_otsu(gray_image)\n",
    "    return gray_image > threshold_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen_image(image):\n",
    "    return unsharp_mask(image, radius=1.0, amount=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_contrast(image):\n",
    "    p2, p98 = np.percentile(image, (2, 98))\n",
    "    return exposure.rescale_intensity(image, in_range=(p2, p98))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_resolution(image):\n",
    "    # Placeholder function for super-resolution, as it requires a trained model or library implementation\n",
    "    return resize(image, (image.shape[0]*2, image.shape[1]*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_image(image):\n",
    "    return denoise_tv_chambolle(image, weight=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_correction(image):\n",
    "    # Placeholder function for color correction\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory if it doesn't exist\n",
    "output_dir = 'output/processed_images'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_images(image_list, output_dir):\n",
    "\n",
    "#     # Iterate over the image list\n",
    "#     for idx, im in enumerate(image_list):\n",
    "#         # Convert PIL image to OpenCV format\n",
    "#         cv_image = np.array(im)\n",
    "\n",
    "#         # Skew Correction\n",
    "#         deskewed_image = deskew(cv_image)\n",
    "\n",
    "#         # Image Scaling\n",
    "#         scaled_image = scale_image(deskewed_image)\n",
    "\n",
    "#         # Noise Removal\n",
    "#         noise_removed_image = remove_noise(scaled_image)\n",
    "\n",
    "#         # Thinning and Skeletonization\n",
    "#         skeletonized_image = thin_skeletonize(noise_removed_image)\n",
    "\n",
    "#         # Binarization\n",
    "#         binary_image = binarize_image(skeletonized_image)\n",
    "\n",
    "#         # Save the processed image\n",
    "#         output_filename = f\"{output_dir}/processed_image_{idx}.jpg\"\n",
    "#         cv2.imwrite(output_filename, binary_image.astype(np.uint8) * 255)\n",
    "\n",
    "#     # Notify user that processing is complete\n",
    "#     print(\"Image processing complete. Processed images saved in 'output/processed_images' directory.\")\n",
    "\n",
    "# # Call the function to process and save the images\n",
    "# output_dir = 'output/processed_images'\n",
    "# save_images(image_list, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_image(processed_image, output_dir, idx):\n",
    "        output_filename = f\"{output_dir}/processed_image_{idx}.jpg\"\n",
    "        cv2.imwrite(output_filename, processed_image.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(image_list, output_dir):\n",
    "# Iterate over the image list\n",
    "    for idx, im in enumerate(image_list):\n",
    "        # Convert PIL image to OpenCV format\n",
    "        cv_image = np.array(im)\n",
    "\n",
    "        \n",
    "\n",
    "        # Skew Correction\n",
    "        deskewed_image = deskew(cv_image)\n",
    "        save_processed_image(deskewed_image,output_dir,idx)\n",
    "        # output_filename = f\"{output_dir}/deskewed_image_{idx}.jpg\"\n",
    "        # cv2.imwrite(output_filename, deskewed_image.astype(np.uint8))\n",
    "\n",
    "        # Image Scaling\n",
    "        # scaled_image = scale_image(cv_image)\n",
    "        # output_filename = f\"{output_dir}/scaled_image_{idx}.jpg\"\n",
    "        # cv2.imwrite(output_filename, scaled_image.astype(np.uint8))\n",
    "\n",
    "        # Noise Removal\n",
    "        # noise_removed_image = remove_noise(cv_image)\n",
    "        # output_filename = f\"{output_dir}/noise_removed_image_{idx}.jpg\"\n",
    "        # cv2.imwrite(output_filename, noise_removed_image.astype(np.uint8))\n",
    "\n",
    "        # Thinning and Skeletonization\n",
    "        # skeletonized_image = thin_skeletonize(cv_image)\n",
    "        # output_filename = f\"{output_dir}/skeletonized_image_{idx}.jpg\"\n",
    "        # cv2.imwrite(output_filename, skeletonized_image.astype(np.uint8))\n",
    "\n",
    "        # Binarization\n",
    "        # binary_image = binarize_image(cv_image)\n",
    "        # output_filename = f\"{output_dir}/binary_image_{idx}.jpg\"\n",
    "        # cv2.imwrite(output_filename, binary_image.astype(np.uint8))\n",
    "\n",
    "    # Notify user that processing is complete\n",
    "    print(\"Image processing complete. Processed images saved in 'output/processed_images' directory.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image processing complete. Processed images saved in 'output/processed_images' directory.\n"
     ]
    }
   ],
   "source": [
    "# Call the function to process and save the images\n",
    "output_dir = 'output/processed_images'\n",
    "save_images(image_list, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
