{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
      "\n",
      "        dataset  \n",
      "0  vidir_modern  \n",
      "1  vidir_modern  \n",
      "2  vidir_modern  \n",
      "3  vidir_modern  \n",
      "4  vidir_modern  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pds\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "np.random.seed(42)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "csv_path = 'dataset\\HAM10000_metadata.csv'\n",
    "# Read the CSV file into a DataFrame\n",
    "skin_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Display the header of the DataFrame\n",
    "print(skin_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
      "\n",
      "        dataset  \n",
      "0  vidir_modern  \n",
      "1  vidir_modern  \n",
      "2  vidir_modern  \n",
      "3  vidir_modern  \n",
      "4  vidir_modern  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'dx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\Roboflow2.0\\zero\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'dx'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# label encoding to numeric values from text\u001b[39;00m\n\u001b[0;32m     45\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m---> 46\u001b[0m le\u001b[38;5;241m.\u001b[39mfit(\u001b[43mdf_images\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     47\u001b[0m LabelEncoder()\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(le\u001b[38;5;241m.\u001b[39mclasses_))\n",
      "File \u001b[1;32md:\\Roboflow2.0\\zero\\Lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\Roboflow2.0\\zero\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3807\u001b[0m     ):\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'dx'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set the desired image and mask directories\n",
    "image_dir = 'dataset/input_images'\n",
    "mask_dir = 'dataset/input_images_mask'\n",
    "\n",
    "# Load mask image list\n",
    "mask_img_list = os.listdir(mask_dir)\n",
    "df_mask_images = pd.DataFrame(mask_img_list, columns=['image_id'])\n",
    "\n",
    "# Load image list\n",
    "img_list = os.listdir(image_dir)\n",
    "df_images = pd.DataFrame(img_list, columns=['image_id'])\n",
    "\n",
    "SIZE = 32\n",
    "\n",
    "# label encoding to numeric values from text\n",
    "le = LabelEncoder()\n",
    "le.fit(df_images['dx'])\n",
    "LabelEncoder()\n",
    "print(list(le.classes_))\n",
    "\n",
    "df_images['label'] = le.transform(df_images[\"dx\"])\n",
    "print(df_images[['dx', 'label']].sample(10))\n",
    "\n",
    "# Data distribution visualization\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "skin_df['dx'].value_counts().plot(kind='bar', ax=ax1)\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Cell Type');\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "skin_df['sex'].value_counts().plot(kind='bar', ax=ax2)\n",
    "ax2.set_ylabel('Count', size=15)\n",
    "ax2.set_title('Sex');\n",
    "\n",
    "ax3 = fig.add_subplot(223)\n",
    "skin_df['localization'].value_counts().plot(kind='bar')\n",
    "ax3.set_ylabel('Count',size=12)\n",
    "ax3.set_title('Localization')\n",
    "\n",
    "ax4 = fig.add_subplot(224)\n",
    "sample_age = skin_df[pd.notnull(skin_df['age'])]\n",
    "sns.distplot(sample_age['age'], fit=stats.norm, color='red');\n",
    "ax4.set_title('Age')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of data into various classes\n",
    "from sklearn.utils import resample\n",
    "print(skin_df['label'].value_counts())\n",
    "\n",
    "# Balance data.\n",
    "# Many ways to balance data...\n",
    "df_0 = skin_df[skin_df['label'] == 0]\n",
    "df_1 = skin_df[skin_df['label'] == 1]\n",
    "df_2 = skin_df[skin_df['label'] == 2]\n",
    "df_3 = skin_df[skin_df['label'] == 3]\n",
    "df_4 = skin_df[skin_df['label'] == 4]\n",
    "df_5 = skin_df[skin_df['label'] == 5]\n",
    "df_6 = skin_df[skin_df['label'] == 6]\n",
    "\n",
    "n_samples=500\n",
    "df_0_balanced = resample(df_0, replace=True, n_samples=n_samples, random_state=42)\n",
    "df_1_balanced = resample(df_1, replace=True, n_samples=n_samples, random_state=42)\n",
    "df_2_balanced = resample(df_2, replace=True, n_samples=n_samples, random_state=42)\n",
    "df_3_balanced = resample(df_3, replace=True, n_samples=n_samples, random_state=42)\n",
    "df_4_balanced = resample(df_4, replace=True, n_samples=n_samples, random_state=42)\n",
    "df_5_balanced = resample(df_5, replace=True, n_samples=n_samples, random_state=42)\n",
    "df_6_balanced = resample(df_6, replace=True, n_samples=n_samples, random_state=42)\n",
    "\n",
    "# Combined back to a single dataframe\n",
    "skin_df_balanced = pd.concat([df_0_balanced, df_1_balanced,\n",
    "                              df_2_balanced, df_3_balanced,\n",
    "                              df_4_balanced, df_5_balanced, df_6_balanced])\n",
    "\n",
    "# Check the distribution. All classes should be balanced now.\n",
    "print(skin_df_balanced['label'].value_counts())\n",
    "\n",
    "# Now time to read images based on image ID from the CSV file\n",
    "image_path = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "              for x in glob(os.path.join(image_dir, '*.jpg'))}\n",
    "# Define the path and add as a new column\n",
    "skin_df_balanced['path'] = skin_df_balanced['image_id'].map(lambda x: os.path.join(image_dir, x))\n",
    "# Use the path to read images.\n",
    "skin_df_balanced['image'] = skin_df_balanced['path'].map(lambda x: np.asarray(Image.open(x).resize((SIZE,SIZE))))\n",
    "\n",
    "n_samples = 5  # number of samples for plotting\n",
    "# Plotting\n",
    "fig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\n",
    "for n_axs, (type_name, type_rows) in zip(m_axs,\n",
    "                                         skin_df_balanced.sort_values(['dx']).groupby('dx')):\n",
    "    n_axs[0].set_title(type_name)\n",
    "    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=1234).iterrows()):\n",
    "        c_ax.imshow(c_row['image'])\n",
    "        c_ax.axis('off')\n",
    "\n",
    "# Convert dataframe column of images into numpy array\n",
    "# Replace 'content/imgs/' with the new image directory\n",
    "X = np.asarray(skin_df_balanced['image'].tolist())\n",
    "X = X/255.0  # Scale values to 0-1.\n",
    "Y=skin_df_balanced['label']  #Assign label values to Y\n",
    "Y_cat = to_categorical(Y, num_classes=7) #Convert to categorical as this is a multiclass classification problem\n",
    "#Split to training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_cat, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define the model.\n",
    "\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(256, (3, 3), activation=\"relu\", input_shape=(SIZE, SIZE, 3)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3),activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['acc'])\n",
    "\n",
    "# Train\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size = batch_size,\n",
    "    validation_data=(x_test, y_test),\n",
    "    verbose=2)\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "# plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Prediction on test data\n",
    "y_pred = model.predict(x_test)\n",
    "# Convert predictions classes to one hot vectors\n",
    "y_pred_classes = np.argmax(y_pred, axis = 1)\n",
    "# Convert test data to one hot vectors\n",
    "y_true = np.argmax(y_test, axis = 1)\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.set(font_scale=1.6)\n",
    "sns.heatmap(cm, annot=True, linewidths=.5, ax=ax)\n",
    "\n",
    "# PLot fractional incorrect misclassifications\n",
    "incorr_fraction = 1 - np.diag(cm) / np.sum(cm, axis=1)\n",
    "plt.bar(np.arange(7), incorr_fraction)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Fraction of incorrect predictions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
